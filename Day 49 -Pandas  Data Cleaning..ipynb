{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3293231-8b08-4408-902c-b9cbec17a42a",
   "metadata": {},
   "source": [
    "# <div style=\"padding:20px;color:white;margin:0;font-size:35px;font-family:Georgia;text-align:left;display:fill;border-radius:5px;background-color:#254E58;overflow:hidden\"><b>Day 49 - Pandas- Data Cleaning</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b50efee-662c-4c05-8a41-adf7ed3ac666",
   "metadata": {},
   "source": [
    "# **Pandas - Cleaning Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18f790c-f184-435a-90f4-d180851510ac",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "**Data cleaning means fixing bad data in your data set.**\n",
    "\n",
    "**Bad data could be:**\n",
    "\n",
    "* Empty cells\n",
    "* Data in wrong format\n",
    "* Wrong data\n",
    "* Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7169f4-1372-4dc0-9c9d-893b083253ef",
   "metadata": {},
   "source": [
    "### **Pandas - Cleaning Empty Cells**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff4e032-6c19-4bf5-b735-3d9cbc4825a6",
   "metadata": {},
   "source": [
    "**Empty cells can potentially give you a wrong result when you analyze data.**\n",
    "\n",
    "**Remove Rows**\n",
    "* One way to deal with empty cells is to remove rows that contain empty cells.\n",
    "\n",
    "* This is usually OK, since data sets can be very big, and removing a few rows will not have a big impact on the result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88eaaab-16ae-41e0-8845-6d04c34a97f3",
   "metadata": {},
   "source": [
    "**Return a new Data Frame with no empty cells:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97d8e7e4-c236-4295-8631-9ec7ff167a99",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data .csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata .csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m new_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(new_df\u001b[38;5;241m.\u001b[39mto_string())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data .csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data .csv')\n",
    "\n",
    "new_df = df.dropna()\n",
    "\n",
    "print(new_df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f6b9e9-ca63-416a-bf99-b9a60770f3f3",
   "metadata": {},
   "source": [
    "**Remove all rows with NULL values:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8816a670-fbce-4dc6-806e-8225990f31b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data .csv')\n",
    "\n",
    "df.dropna(inplace = True)\n",
    "\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160f7d1a-63a2-4990-a33b-580164279394",
   "metadata": {},
   "source": [
    "### Replace Empty Values\n",
    "* Another way of dealing with empty cells is to insert a new value instead.\n",
    "\n",
    "* This way you do not have to delete entire rows just because of some empty cells.\n",
    "\n",
    "* The fillna() method allows us to replace empty cells with a value:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28996988-8ce0-4b2a-a3e6-a7146c9f8271",
   "metadata": {},
   "source": [
    "**Replace NULL values with the number 130:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfd62af-9b95-4da5-ae54-fce5020be0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data .csv')\n",
    "\n",
    "df.fillna(130, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b214e2-5f51-4588-a85a-f48963ba878a",
   "metadata": {},
   "source": [
    "### Replace Only For Specified Columns\n",
    "* The example above replaces all empty cells in the whole Data Frame.\n",
    "\n",
    "* To only replace empty values for one column, specify the column name for the DataFrame:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320c8e84-3d99-41bd-900f-5524dcd088e5",
   "metadata": {},
   "source": [
    "**Replace NULL values in the \"Calories\" columns with the number 130:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d804ef45-edc7-4d32-88b8-9a7c9132f228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data .csv')\n",
    "\n",
    "df[\"Calories\"].fillna(130, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b43d59-0304-41e6-99ea-f13c875eb1e0",
   "metadata": {},
   "source": [
    "### Replace Using Mean, Median, or Mode\n",
    "* A common way to replace empty cells, is to calculate the mean, median or mode value of the column.\n",
    "\n",
    "* Pandas uses the mean() median() and mode() methods to calculate the respective values for a specified column:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f19029-b16d-4050-a02f-b98725bb6b56",
   "metadata": {},
   "source": [
    "**Calculate the MEAN, and replace any empty values with it:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e5ce91-f403-4279-9d42-56d2942b0091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data .csv')\n",
    "\n",
    "x = df[\"Calories\"].mean()\n",
    "\n",
    "df[\"Calories\"].fillna(x, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5fb4d6-5c24-42a9-a919-9bb9e624e9da",
   "metadata": {},
   "source": [
    "**Calculate the MEDIAN, and replace any empty values with it:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54193995-9f65-49d8-af78-bb3f69a4177f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data .csv')\n",
    "\n",
    "x = df[\"Calories\"].median()\n",
    "\n",
    "df[\"Calories\"].fillna(x, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b85a247-273a-4932-9ba0-08e3b3a08c78",
   "metadata": {},
   "source": [
    "**Calculate the MODE, and replace any empty values with it:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bb950f-72e7-4279-a8e1-f1619b96dc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data .csv')\n",
    "\n",
    "x = df[\"Calories\"].mode()[0]\n",
    "\n",
    "df[\"Calories\"].fillna(x, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49daa189-2094-48d8-857e-2b4590617a70",
   "metadata": {},
   "source": [
    "## Cleaning Data of Wrong Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3093ab98-cb8e-40d8-b26a-e68d76adbfb4",
   "metadata": {},
   "source": [
    "**Data of Wrong Format**\n",
    "* Cells with data of wrong format can make it difficult, or even impossible, to analyze data.\n",
    "\n",
    "* To fix it, you have two options: remove the rows, or convert all cells in the columns into the same format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3deaa85-dbc8-41e5-930d-1f76222c5349",
   "metadata": {},
   "source": [
    "## Convert Into a Correct Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85fc175-3729-4a1f-8801-42598323be18",
   "metadata": {},
   "source": [
    "**Convert to date:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18d08b7-0f26-4640-b735-e847c8913da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Data.csv')\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179d418e-5885-43a2-97a1-4d17cb7c0f5a",
   "metadata": {},
   "source": [
    "### Removing Rows\n",
    "* The result from the converting in the example above gave us a NaT value, which can be handled as a NULL value, and we can remove the row by using the dropna() method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07426cd-61af-4ebb-be16-ceb1e5eca906",
   "metadata": {},
   "source": [
    "**Remove rows with a NULL value in the \"Date\" column:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a2c2c8-0489-4527-8036-7bb2d732ae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['Date'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71eb981-31b3-42c1-bb3f-407afc8555c5",
   "metadata": {},
   "source": [
    "## Fixing Wrong Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44701f5a-016e-4b96-a708-9784e053bc37",
   "metadata": {},
   "source": [
    "### Replacing Values\n",
    "* One way to fix wrong values is to replace them with something else.\n",
    "\n",
    "* In  this program , it is most likely a typo, and the value should be \"45\" instead of \"450\", and we could just insert \"45\" in row 7:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bc12a1-fec9-4615-85a6-95cdb13333e1",
   "metadata": {},
   "source": [
    "**Set \"Duration\" = 45 in row 7:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a1b01a-1c3e-4e19-bf92-521ebb6abcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[7, 'Duration'] = 45\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce35f052-6f5b-4b1b-95a3-cf0cb1109915",
   "metadata": {},
   "source": [
    "**Loop through all values in the \"Duration\" column.**\n",
    "\n",
    "**If the value is higher than 120, set it to 120:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417c5550-3e0c-4ed7-a7ff-d6027db9fa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in df.index:\n",
    "  if df.loc[x, \"Duration\"] > 120:\n",
    "    df.loc[x, \"Duration\"] = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5d280c-4fd1-4ba0-b19f-7bb2b058b6eb",
   "metadata": {},
   "source": [
    "### Removing Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf929b5-eae7-4db1-a343-72c50596c455",
   "metadata": {},
   "source": [
    "**Delete rows where \"Duration\" is higher than 120:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0400b295-40b2-44cf-8fc7-6fd93bd45144",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in df.index:\n",
    "  if df.loc[x, \"Duration\"] > 120:\n",
    "    df.drop(x, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda3e160-9867-44ea-a3c0-b34c8b9a7db2",
   "metadata": {},
   "source": [
    "## Removing Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51628bfe-0b46-4bb2-af6c-2088e1ef9e57",
   "metadata": {},
   "source": [
    "**Returns True for every row that is a duplicate, otherwise False:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd38539-375a-4540-877e-117c19c00725",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.duplicated())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca19ee4-f47e-4f7e-b317-844e77b32d0b",
   "metadata": {},
   "source": [
    "**Remove all duplicates:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86b9250-af79-400f-87b8-eaa8cf30182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47eec494-368a-4946-ac93-4da6e66c63e8",
   "metadata": {},
   "source": [
    "## **Data Correlations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a25e1c7-1fea-49d3-9532-2fdf5f454da1",
   "metadata": {},
   "source": [
    "### Finding Relationships\n",
    "* A great aspect of the Pandas module is the corr() method.\n",
    "\n",
    "* The corr() method calculates the relationship between each column in your data set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2e9779-a5f0-4b74-8d49-d6843d6fa670",
   "metadata": {},
   "source": [
    "### **Show the relationship between the columns:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d1475d-fe74-41a7-aaf4-b9e7e0b36ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bc447f-d4cd-4826-a9cf-7b57be7a4e72",
   "metadata": {},
   "source": [
    "**Result Explained**:\n",
    "* The Result of the corr() method is a table with a lot of numbers that represents how well the relationship is between two columns.\n",
    "\n",
    "* The number varies from -1 to 1.\n",
    "\n",
    "* 1 means that there is a 1 to 1 relationship (a perfect correlation), and for this data set, each time a value went up in the first column, the other one went up as well.\n",
    "\n",
    "* 0.9 is also a good relationship, and if you increase one value, the other will probably increase as well.\n",
    "\n",
    "* -0.9 would be just as good relationship as 0.9, but if you increase one value, the other will probably go down.\n",
    "\n",
    "* 0.2 means NOT a good relationship, meaning that if one value goes up does not mean that the other will.\n",
    "\n",
    "**What is a good correlation? It depends on the use, but I think it is safe to say you have to have at least 0.6 (or -0.6) to call it a good correlation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6ac20e-016a-4a01-8057-72e5be37c117",
   "metadata": {},
   "source": [
    "## Perfect Correlation:\n",
    "* We can see that \"Duration\" and \"Duration\" got the number 1.000000, which makes sense, each column always has a perfect relationship with itself.\n",
    "\n",
    "## Good Correlation:\n",
    "* \"Duration\" and \"Calories\" got a 0.922721 correlation, which is a very good correlation, and we can predict that the longer you work out, the more calories you burn, and the other way around: if you burned a lot of calories, you probably had a long work out.\n",
    "\n",
    "## Bad Correlation:\n",
    "* \"Duration\" and \"Maxpulse\" got a 0.009403 correlation, which is a very bad correlation, meaning that we can not predict the max pulse by just looking at the duration of the work out, and vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3f227d-5775-4421-8fce-39fe1e45c210",
   "metadata": {},
   "source": [
    "## **Plotting**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4088df-0dd8-4cc7-be29-a8f95dee7c25",
   "metadata": {},
   "source": [
    "* Pandas uses the plot() method to create diagrams.\n",
    "\n",
    "* We can use Pyplot, a submodule of the Matplotlib library to visualize the diagram on the screen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94d79d2-18de-422d-a8b9-3a6b752e6222",
   "metadata": {},
   "source": [
    "## Import pyplot from Matplotlib and visualize our DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077bebf4-0f4d-48f3-9ded-e9ac2eaf1b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('Data.csv')\n",
    "\n",
    "df.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639b95c2-c360-4609-ab90-3e322d50b047",
   "metadata": {},
   "source": [
    "## Scatter Plot\n",
    "* Specify that you want a scatter plot with the kind argument:\n",
    "\n",
    "* kind = 'scatter'\n",
    "\n",
    "* A scatter plot needs an x- and a y-axis.\n",
    "\n",
    "* In the code below we will use \"Duration\" for the x-axis and \"Calories\" for the y-axis.\n",
    "\n",
    "* Include the x and y arguments like this:\n",
    "\n",
    "* x = 'Duration', y = 'Calories'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c715e9c-7a7f-46e4-8fa9-f385fca81407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "df.plot(kind = 'scatter', x = 'Duration', y = 'Calories')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0d25ff-08e5-4adb-9008-053c27b4bc9a",
   "metadata": {},
   "source": [
    "## A scatterplot where there are no relationship between the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdabeb91-337d-42e7-a783-f2cc2b6d0253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "df.plot(kind = 'scatter', x = 'Duration', y = 'Maxpulse')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dc0df8-43ee-4027-9e2c-39a7cf2ca6ca",
   "metadata": {},
   "source": [
    "## Histogram\n",
    "* Use the kind argument to specify that you want a histogram:\n",
    "\n",
    "* kind = 'hist'\n",
    "\n",
    "* A histogram needs only one column.\n",
    "\n",
    "* A histogram shows us the frequency of each interval, e.g. how many workouts lasted between 50 and 60 minutes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74a0216-6b9e-4288-bc84-a3383d9dcb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Duration\"].plot(kind = 'hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73a51cc-22ce-42b2-a3b7-7efb6d5aa4b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9257f44-aa8f-4ea5-864b-9199d1e53210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
